{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Network Deployment\n",
    "\n",
    "By Jon Barker and Ryan Olson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to NVIDIA's deep learning network deployment lab.  This lab  will use DIGITS, Caffe and the GPU Inference Engine (GIE) for deploying deep neural networks trained in DIGITS. You will learn some of the factors that affect data throughput and latency during neural network inference.  You will also see an example of how to use a neural network for efficient image classification within an easily deployable web service using the GPU Inference Engine (GIE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Inference using DIGITS\n",
    "\n",
    "Deep-learning networks typically have two primary phases of development: training and inference\n",
    "\n",
    "### Neural network training and inference\n",
    "\n",
    "Solving a supervised machine learning problem with deep neural networks involves a two-step process.\n",
    "\n",
    "The first step is to train a deep neural network on massive amounts of labeled data using GPUs. During this step, the neural network learns millions of weights or parameters that enable it to map input data examples to correct responses. Training requires iterative forward and backward passes through the network as the objective function is minimized with respect to the network weights. Often several models are trained and accuracy is validated against data not seen during training in order to estimate real-world performance.\n",
    "\n",
    "![](files/dnn.png)\n",
    "\n",
    "The next step – inference – uses the trained model to make predictions from new data. During this step, the best trained model is used in an application running in a production environment such as a data center, an automobile, or an embedded platform. For some applications, such as autonomous driving, inference is done in real time and therefore high throughput is critical.  The typical training and inference cycle is depicted below.\n",
    "\n",
    "<img src=\"files/digits_workflow.png\" alt=\"Drawing\" style=\"width: =800px;\"/>\n",
    "\n",
    "Due to the size of the datasets and deep neural networks, training is typically very resource-intensive and can take weeks or months on traditional compute architectures. However, using GPUs greatly accelerates this process down to days or hours.\n",
    "\n",
    "Due to the depth of deep neural networks, inference also requires significant compute resources to process in realtime on imagery or other high-volume sensor data. However, GPU acceleration can also be utilized during inference whether it in a data center processing incoming web queries or on the [Jetson TX1](http://www.nvidia.com/object/jetson-tx1-module.html)'s integrated NVIDIA GPU deployed onboard embedded platforms. This enables real-time inference in robotics applications like picking, autonomous navigation, agriculture, and industrial inspection.\n",
    "\n",
    "Using DIGITS, anyone can easily get started and interactively train their networks with GPU acceleration. \n",
    "DIGITS is an open-source project contributed by NVIDIA, located here: https://github.com/NVIDIA/DIGITS.  However, DIGITS is also the starting point for deploying a trained neural network.\n",
    "\n",
    "### Inference using DIGITS\n",
    "\n",
    "Now click [here](/digits/) to open DIGITS in a separate tab.  If at any time DIGITS asks you to login you just make up a username and proceed.\n",
    "\n",
    "The DIGITS server you will see running contains two neural networks listed under the `\"Pretrained Models\"` tab:\n",
    "\n",
    "![](files/pretrained.png)\n",
    "\n",
    "- *GoogleNet* is a well known convolutional neural network (CNN) architecture that has been trained for image classification using  the [ilsvrc12 Imagenet](http://www.image-net.org/challenges/LSVRC/2012/) dataset.  This network can assign one of 1000 class class labels to an entire image based on the dominant object present. The classes this model can recognize can be found [here](http://image-net.org/challenges/LSVRC/2012/browse-synsets).\n",
    "\n",
    "- *pedestrian_detectNet* is another CNN architecture that is not only able to assign a global classification to an image but can go further and detect multiple objects within the image and draw bounding boxes around them.  The pre-trained model provided has been trained for the task of pedestrian detection using a large dataset of pedestrians in a variety of indoor and outdoor scenes.\n",
    "\n",
    "Any pre-trained model in DIGITS can be immediately applied to a new test image through the same browser interface. Click on the name of one of the models to see the model summary view.  At the bottom of this view you will see the `\"Inference Options\"` section.  Here you can select to apply the model to a single test image, a whole LMDB database of test images or a list of files referenced in a text file.  \n",
    "\n",
    "**Exercise:** Complete the following steps to test a single image that resides on the same server as the running DIGITS instance:\n",
    "\n",
    "![](files/digits_inference.png)\n",
    "\n",
    "If you successfully follow these steps you should see one of the inference outputs below:\n",
    "\n",
    "![](files/digits_inference_outputs.png)\n",
    "\n",
    "(**Optional Exercise**) Carry out the same inference task again using DetectNet but this time select a version of the model from an earlier epoch in the training process using `\"Select Model`\" dropdown.  You should find that models from earlier epochs produce less accurate detection results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Inference using pycaffe\n",
    "\n",
    "In production deployment scenarios it is desirable to carry out inference programatically through a deep learning framework API. The inference job that DIGITS just completed made use of the underlying Caffe deep learning framework through it's Python API pycaffe. We will now walk through a simple example Python application that uses pycaffe to detect pedestrians in a test image using the pretrained DetectNet model introduced in Part 1.  Note that this example is representative of the way that inference is carried out in the majority of deep learning frameworks.\n",
    "\n",
    "A model trained in DIGITS can be imported into pycaffe as an instance of the `caffe.Net` class.  You can find the path of the directory containing the model definition files and trained model weights listed under **Job Directory\n",
    "** at the top of the model's page in DIGITS.  For example:\n",
    "\n",
    "<img src=\"files/digits_job.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Simlarly if you look at the corresponding dataset in DIGITS you can find the **Job Directory** containing the dataset mean image.\n",
    "\n",
    "**Exercise:** Find the job directory for the pedestrian_detectnet model and the pedestrian_dummy_dataset and use them as the `MODEL_JOB_DIR` and `DATA_JOB_DIR` parameters in the code cells below to apply DetectNet to a sequence of test frames from the video `melbourne.mp4` using pycaffe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required Python libraries\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "import caffe\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure Caffe to use the GPU for inference\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the model job directory from DIGITS here\n",
    "MODEL_JOB_DIR='/home/ubuntu/digits/digits/jobs/20160905-143028-2f08'\n",
    "# Set the data job directory from DIGITS here\n",
    "DATA_JOB_DIR='/home/ubuntu/digits/digits/jobs/20160905-135347-01d5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to find the iteration number of the final model snapshot saved by DIGITS\n",
    "for root, dirs, files in os.walk(MODEL_JOB_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith('.solverstate'):\n",
    "            last_iteration = f.split('_')[2].split('.')[0]\n",
    "print 'Last snapshot was after iteration: ' + last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset mean image file\n",
    "mean = np.load(os.path.join(DATA_JOB_DIR,'train_db','mean.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate a Caffe model in GPU memory\n",
    "# The model architecture is defined in the deploy.prototxt file\n",
    "# The pretrained model weights are contained in the snapshot_iter_<number>.caffemodel file\n",
    "classifier = caffe.Net(os.path.join(MODEL_JOB_DIR,'deploy.prototxt'), \n",
    "                       os.path.join(MODEL_JOB_DIR,'snapshot_iter_' + last_iteration + '.caffemodel'),\n",
    "                       caffe.TEST)\n",
    "\n",
    "# Instantiate a Caffe Transformer object that wil preprocess test images before inference\n",
    "transformer = caffe.io.Transformer({'data': classifier.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data',mean.mean(1).mean(1)/255)\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "\n",
    "BATCH_SIZE, CHANNELS, HEIGHT, WIDTH = classifier.blobs['data'].data[...].shape\n",
    "\n",
    "print 'The input size for the network is: (' + \\\n",
    "        str(BATCH_SIZE), str(CHANNELS), str(HEIGHT), str(WIDTH) + \\\n",
    "         ') (batch size, channels, height, width)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create opencv video object\n",
    "vid = cv2.VideoCapture('/home/ubuntu/deployment_lab/melbourne.mp4')\n",
    "\n",
    "# We will just use every n-th frame from the video\n",
    "every_nth = 10\n",
    "counter = 0\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture video frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        counter += 1\n",
    "        \n",
    "        if not ret:\n",
    "            \n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Mesddage to be displayed after releasing the device\n",
    "            print \"Released Video Resource\"\n",
    "            break\n",
    "        if counter%every_nth == 0:\n",
    "            \n",
    "            # Resize the captured frame to match the DetectNet model\n",
    "            frame = cv2.resize(frame, (1024, 512), 0, 0)\n",
    "            \n",
    "            # Use the Caffe transformer to preprocess the frame\n",
    "            data = transformer.preprocess('data', frame.astype('float16')/255)\n",
    "            \n",
    "            # Set the preprocessed frame to be the Caffe model's data layer\n",
    "            classifier.blobs['data'].data[...] = data\n",
    "            \n",
    "            # Measure inference time for the feed-forward operation\n",
    "            start = time.time()\n",
    "            # The output of DetectNet is an array of bounding box predictions\n",
    "            bounding_boxes = classifier.forward()['bbox-list'][0]\n",
    "            end = (time.time() - start)*1000\n",
    "            \n",
    "            # Convert the image from OpenCV BGR format to matplotlib RGB format for display\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Create a copy of the image for drawing bounding boxes\n",
    "            overlay = frame.copy()\n",
    "            \n",
    "            # Loop over the bounding box predictions and draw a rectangle for each bounding box\n",
    "            for bbox in bounding_boxes:\n",
    "                if  bbox.sum() > 0:\n",
    "                    cv2.rectangle(overlay, (bbox[0],bbox[1]), (bbox[2],bbox[3]), (255, 0, 0), -1)\n",
    "                    \n",
    "            # Overlay the bounding box image on the original image\n",
    "            frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)\n",
    "            \n",
    "            # Display the inference time per frame\n",
    "            cv2.putText(frame,\"Inference time: %dms per frame\" % end,\n",
    "                        (10,500), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "\n",
    "            # Display the frame\n",
    "            imshow(frame)\n",
    "            show()\n",
    "            # Display the frame until new frame is available\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "# At any point you can stop the video playback and inference by  \n",
    "# clicking on the stop (black square) icon at the top of the notebook\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print \"Released Video Resource\"            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see pycaffe can carry out DetectNet inference on a 1024x512 video frame in a time of about 73ms.  Clearly the video playback is much slower than this due to the overhead of reading frames from the video and drawing the output frame with bounding box overlays.  There is also a startup cost associated with initializing the model in memory.  In a production system you would often try to have the data ingest and output postprocessing taking place in a separate parallel thread to the Caffe inference.  You would also keep the model initialized in GPU memory to accept new data at any time without incurring the startup overhead again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some applications we are less worried about the inference time for an indvidual frame (latency) and more concerned with how many frames we can process in a unit of time (throughput).  In these situations we can carry out inference as a batch process, just like during training.  In the case of video this would mean buffering frames until a batch is full and then carrying out inference.\n",
    "\n",
    "**Exercise:** Modify the code cell below to carry out inference on the same video as before but with batch sizes 1, 2, 5 and 8.  Compare the per frame inference time and throughput.  \n",
    "\n",
    "NOTE: If you try a batch size greater than 8 you will run out of GPU memory and see an error from the notebook.  This is fine to do, but you will have to re-execute the previous code cells to get back to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEW_BATCH_SIZE = 2\n",
    "\n",
    "# Resize the input data layer for the new batch size\n",
    "OLD_BATCH_SIZE, CHANNELS, HEIGHT, WIDTH = classifier.blobs['data'].data[...].shape\n",
    "classifier.blobs['data'].reshape(NEW_BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "classifier.reshape()\n",
    "\n",
    "# Create opencv video object\n",
    "vid = cv2.VideoCapture('/home/ubuntu/deployment_lab/melbourne.mp4')\n",
    "\n",
    "counter = 0\n",
    "\n",
    "batch = np.zeros((NEW_BATCH_SIZE, HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture video frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Mesddage to be displayed after releasing the device\n",
    "            print \"Released Video Resource\"\n",
    "            break\n",
    "            \n",
    "        # Resize the captured frame to match the DetectNet model\n",
    "        frame = cv2.resize(frame, (WIDTH, HEIGHT), 0, 0)\n",
    "        \n",
    "        # Add frame to batch array\n",
    "        batch[counter%NEW_BATCH_SIZE,:,:,:] = frame\n",
    "        counter += 1\n",
    "        \n",
    "        if counter%NEW_BATCH_SIZE==0:\n",
    "        \n",
    "            # Use the Caffe transformer to preprocess the frame\n",
    "            data = transformer.preprocess('data', frame.astype('float16')/255)\n",
    "            \n",
    "            # Set the preprocessed frame to be the Caffe model's data layer\n",
    "            classifier.blobs['data'].data[...] = data\n",
    "            \n",
    "            # Measure inference time for the feed-forward operation\n",
    "            start = time.time()\n",
    "            # The output of DetectNet is now an array of bounding box predictions\n",
    "            # for each image in the input batch\n",
    "            bounding_boxes = classifier.forward()['bbox-list']\n",
    "            end = (time.time() - start)*1000\n",
    "            \n",
    "            print 'Inference time: %dms per batch, %dms per frame, output size %s' % \\\n",
    "                    (end, end/NEW_BATCH_SIZE, bounding_boxes.shape)\n",
    "            \n",
    "# At any point you can stop the video playback and inference by  \n",
    "# clicking on the stop (black square) icon at the top of the notebook\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    print \"Released Video Resource\"      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have found that per frame inference time decreases as batch size increases (higher throughput) but the time to process a whole batch also increases (higher latency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: NVIDIA GPU Inference Engine\n",
    "\n",
    "NVIDIA [GPU Inference Engine](https://developer.nvidia.com/gpu-inference-engine) (GIE) is a high-performance deep learning inference solution for production environments. Power efficiency and speed of response are two key metrics for deployed deep learning applications, because they directly affect the user experience and the cost of the service provided. GIE automatically optimizes trained neural networks for run-time performance and delivers GPU-accelerated inference for web/mobile, embedded and automotive applications.\n",
    "\n",
    "![GIE](GIE_Graphics_FINAL-1.png)\n",
    "\n",
    "There are two phases in the use of GIE: build and deployment. In the build phase, GIE performs optimizations on the network configuration and generates an optimized plan for computing the forward pass through the deep neural network. The plan is an optimized object code that can be serialized and stored in memory or on disk.\n",
    "\n",
    "The GIE runtime needs three files to deploy a classification neural network:\n",
    "\n",
    "1. a network architecture file (deploy.prototxt),\n",
    "2. trained weights (net.caffemodel), and\n",
    "3. a label file to provide a name for each output class.\n",
    "\n",
    "These can all be obtained from a trained DIGITS model.  In addition, you must define the batch size and the output layer.\n",
    "\n",
    "GIE supports the following layer types:\n",
    "\n",
    "- Convolution: 2D\n",
    "- Activation: ReLU, tanh and sigmoid\n",
    "- Pooling: max and average\n",
    "- ElementWise: sum, product or max of two tensors\n",
    "- LRN: cross-channel only\n",
    "- Fully-connected: with or without bias\n",
    "- SoftMax: cross-channel only\n",
    "- Deconvolution\n",
    "\n",
    "We are going to build a GIE runtime for the GoogleNet model trained in DIGITS introduced in Part 1.  \n",
    "\n",
    "The `InferenceEngine.cpp` file in the editor below takes a Caffe model and generates a GIE object.  In particular, the builder (lines 36-42) are responsible for reading the network information from the Caffe .prototxt and .caffemodel files.  The builder can also be used to define network information directly if no .prototxt file is available.\n",
    "\n",
    "Other significant lines to inspect in this file are:\n",
    "\n",
    "- line 46 - the output layer from the network is chosen, we are using the \"softmax\" layer as we want to classify images.  If we wished to use GIE to extract features from an intermediate layer of the network we could specify that layer by name here.\n",
    "- line 49 - we choose the maximium input batch size that will be used.  In this example we simply process one image at a time (batch size 1), but if we wished to maximize throughput at the expense of latency we could process larger batches.\n",
    "- line 50 - GIE performs layer optimizations to reduce inference time.  While this is transparent to the user, analyzing the network layers requires memory, so you must specify the maximum workspace size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe id=\"task1\" src=\"task1\" width=\"100%\" height=\"400px\">\n",
    "    <p>Your browser does not support iframes.</p>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished inspecting the InferenceEngine.cpp code execute the command below to build the simple create_plan application which will call InferenceEngine and serialize the generated GIE object to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd /home/ubuntu/GRE_Web_Demo/GIEEngine/src/ && make && \\\n",
    "echo \"create_plan app created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the create_plan application to generate a GIE object from our GoogleNet model trained in DIGITS.  Execute the cell below to do this - the final line specifies where the GIE object (sometimes called a plan) will be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!/home/ubuntu/GRE_Web_Demo/GIEEngine/src/create_plan \\\n",
    "~/digits/digits/jobs/20160908-203605-e46b/deploy.prototxt \\\n",
    "~/digits/digits/jobs/20160908-203605-e46b/snapshot_iter_32.caffemodel \\\n",
    "~/GRE_Web_Demo/GIEEngine/src/imagenet.plan && \\\n",
    "echo \"Plan created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIE performs several important transformations and optimizations to the neural network graph. First, layers with unused output are eliminated to avoid unnecessary computation. Next, where possible convolution, bias, and ReLU layers are fused to form a single layer. Layer fusion improves the efficiency of running GIE-optimized networks on the GPU.\n",
    "\n",
    "Another transformation is horizontal layer fusion, or layer aggregation, along with the required division of aggregated layers to their respective outputs. Horizontal layer fusion improves performance by combining layers that take the same source tensor and apply the same operations with similar parameters, resulting in a single larger layer for higher computational efficiency.\n",
    "\n",
    "For more information on these transformations see the GIE Parallel Forall blog post [here](https://devblogs.nvidia.com/parallelforall/production-deep-learning-nvidia-gpu-inference-engine/).\n",
    "\n",
    "The full scope of batching and streaming data to and from the runtime inference engine is beyond the scope of this lab.  However, the `classification.cpp` file in the editor below contains the key steps required to use the inference engine to process a batch of input data and generate a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe id=\"task2\" src=\"task2\" width=\"100%\" height=\"400px\">\n",
    "    <p>Your browser does not support iframes.</p>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this lab, we have created a [Docker](https://www.docker.com/) container called gre_gie that contains an application called GIE that uses `classifiation.cpp` to instantiate a GIE inference engine from the plan we created and process images that it is passed through a REST service.\n",
    "\n",
    "Execute the cell below to use [NVIDIA Docker](https://github.com/NVIDIA/nvidia-docker) to launch the gre_gie container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run \\\n",
    "    -d --name gre_gie -p 8085:8000 \\\n",
    "    -v /home/ubuntu/GRE_Web_Demo/GIEEngine/src:/inference-engine:ro \\\n",
    "    -v /home/ubuntu/caffe/data/ilsvrc12:/imagenet:ro \\\n",
    "    gre_gie \\\n",
    "    /inference-engine/imagenet.plan \\\n",
    "    /imagenet/imagenet_mean.binaryproto \\\n",
    "    /imagenet/synset_words.txt && \\\n",
    "echo \"GIE container running\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also created a second container called gre_caffegpu that carries out inference on images passed through a REST servcice but uses GPU accelerated Caffe instead of GIE.  The Caffe container uses the same native Caffe model for inference as we used to create the GIE plan above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run \\\n",
    "    -d --name gre_caffegpu -p 8082:8000 \\\n",
    "    -v /home/ubuntu/digits/digits/jobs/20160908-203605-e46b:/model:ro \\\n",
    "    -v /home/ubuntu/caffe/data/ilsvrc12:/imagenet:ro \\\n",
    "    gre_caffegpu \\\n",
    "    /model/deploy.prototxt \\\n",
    "    /model/snapshot_iter_32.caffemodel \\\n",
    "    /imagenet/imagenet_mean.binaryproto \\\n",
    "    /imagenet/synset_words.txt && \\\n",
    "echo \"Caffe GPU container running\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we created a Docker container called gre_frontend that generates a simple web interface that you can upload an image to and have it classified using either the GIE application in the gre_gie container or native GPU Caffe in the gre_caffegpu container.\n",
    "\n",
    "Execute the cell below to start the web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --name gre_frontend -d --net=host gre_frontend FrontEnd \\\n",
    "    \"0.0.0.0:8080\" \\\n",
    "    \"0.0.0.0:8081\" \\\n",
    "    \"0.0.0.0:8082\" \\\n",
    "    \"0.0.0.0:8083\" \\\n",
    "    \"0.0.0.0:8084\" \\\n",
    "    \"0.0.0.0:8085\" \\\n",
    "    \"0.0.0.0:8086\" && \\\n",
    "echo \"GIE web demo container running\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you have received the \"GIE container running\", \"Caffe GPU container running\" and \"GIE web demo container running\" messages above**, click [here](/gre/) to connect to the GIE web interface in a separate tab.\n",
    "\n",
    "You should see a screen like this:\n",
    "\n",
    "![](files/GRE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now classify an image provided through the web interface through either the running GIE or Caffe containers. Either click [here](files/test_images/GN_test.png) to open our GoogleNet test image and save it to disk or if you wish you can use your own test image in .png or .jpeg format:\n",
    "\n",
    "1. Click on \"Image Classification\" in the top left corner\n",
    "2. Click choose file and point to your test image\n",
    "3. Click either the \"Caffe\" or \"GIE\" buttons to pass the image to the running GIE or Caffe container for classification\n",
    "4. Click both the \"profile\" buttons to plot the time taken for making the web request, image preprocessing and inference using GIE and Caffe\n",
    "\n",
    "You should see an output like this:\n",
    "\n",
    "![](files/GREoutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the inference time here includes image preprocessing and the overhead of making a web request, so it is not a true representation of the maximum possible inference speed of GIE or Caffe and it is also running an older K520 GPU.  However, we see that the GIE inference time (dark green bar) is lower than the Caffe time (light green bar).\n",
    "\n",
    "At the end of the day, the success of GIE comes down to the performance it provides for inference. To measure the performance benefits we compared the per-layer timings of the GoogLeNet network using Caffe and GIE on NVIDIA Tesla M4 GPUs with a batch size of 1 averaged over 1000 iterations with GPU clocks fixed in the P0 state.\n",
    "\n",
    "![](files/GIE_GoogLeNet_top10kernels-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stop and remove any existing docker containers\n",
    "!sudo docker stop $(docker ps -a -q)\n",
    "!sudo docker rm $(docker ps -a -q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
